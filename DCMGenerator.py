from collections import Counter
import PowerLawDistribution as pld
import matplotlib.pyplot as plt
import networkx as nx
import operator
import ValidDegree as vd
import scipy.stats as st
import DCMRevised as dcm_r
import numpy as np

class DCMGenerator(object):

    def __init__(self, a, d, beta, n, algorithm):


        if algorithm == 'Erased':
            self.fg = pld.PowerLaw(a, d, beta)
            degree_seq = vd.directed_gen(d, beta, self.fg, n)

            # after modifying the degree sequence to make the sum(d_in) = sum(d_out) using alg 2.1
            self.mean_equal_sum_in_seq = np.mean(degree_seq[0])
            self.mean_equal_sum_out_seq = np.mean(degree_seq[1])
            self.d_in = degree_seq[0].tolist()
            self.d_out = degree_seq[1].tolist()

            # original degree sequence generated by fg-distribution
            self.mean_original_in_seq = np.mean(degree_seq[2])
            self.mean_original_out_seq = np.mean(degree_seq[3])
            self.d_in_original = degree_seq[2].tolist()
            self.d_out_original = degree_seq[3].tolist()

            # generate the multigraph
            dcm = nx.directed_configuration_model(self.d_in, self.d_out)

            # remove parallel edges
            dcm = nx.DiGraph(dcm)
            # remove self-loops
            dcm.remove_edges_from(dcm.selfloop_edges())

            # get the simple directed configuration graph
            self.graph = dcm

        if algorithm == 'Repeated':
            flag = False
            while not flag:
                self.fg = pld.PowerLaw(a, d, beta)
                degree_seq = vd.directed_gen(d, beta, self.fg, n)

                # after modifying the degree sequence to make the sum(d_in) = sum(d_out) using alg 2.1
                self.d_in = degree_seq[0].tolist()
                self.d_out = degree_seq[1].tolist()

                # original degree sequence generated by fg-distribution
                self.d_in_original = degree_seq[2].tolist()
                self.d_out_original = degree_seq[3].tolist()

                (model, flag) = dcm_r.directed_configuration_model_revised(self.d_in, self.d_out)
            self.graph = nx.DiGraph(model)

        # return to a dictionary
        self.page_rank = nx.pagerank(self.graph)
        self.betweenness_centrality = nx.betweenness_centrality(self.graph)
        self.scaled_betweenness_centrality = [elem/sum(list(dcm_erased_ls[j][i].betweenness_centrality)) for elem in list(dcm_erased_ls[j][i].betweenness_centrality)]


        self.graph_din = list(self.graph.in_degree().values())
        self.graph_dout = list(self.graph.out_degree().values())
        self.size = len(self.graph_din)
        self.mean_in_degree = sum(self.graph_din) / self.size
        self.mean_out_degree = sum(self.graph_dout) / self.size

    def __str__(self):
        s = "The params are:\n"
        s += "Expectation of W^minus is " + repr(model.fg.e_w_minus) + '\n'
        s += "Expectation of W^plus is " + repr(model.fg.e_w_plus) + '\n'
        s += '\n'

        s += "Mean of original in-degree sequence is " + repr(self.mean_original_in_seq) + '\n'
        s += "Mean of original out-degree sequence is " + repr(self.mean_original_out_seq) + '\n'
        s += '\n'

        s += "After being modified by Algorithm 2.1, \n"
        s += "Mean of equal-sum in-degree sequence is " + repr(self.mean_equal_sum_in_seq) + '\n'
        s += "Mean of equal-sum out-degree sequence is " + repr(self.mean_equal_sum_out_seq) + '\n'
        s += '\n'

        s += "After removing self-loops and parallel edges:\n"
        s += "Mean of in-degree sequnces is " + repr(self.mean_in_degree) + '\n'
        s += "Mean of out-degree sequnces is " + repr(self.mean_out_degree) + '\n'
        s += '\n'

        return s

    def plot_helper(self, seq, color, ms):
        values = sorted(set(seq))
        hist = [Counter(seq)[x] for x in values]
        plt.plot(values, hist, color, ms)  # in-degree


    def test_equal_sum_algorithm(self):
        """
        method that plots the degree distribution of 
        1) bi-sequence, generated by fg-distribution
        2) bi-sequence, modified by algorithm 2.1 to make equal sum   
        """
        plt.figure()

        self.plot_helper(self.d_in_original, 'bo-', 5)
        self.plot_helper(self.d_out_original, 'gv-', 5)
        self.plot_helper(self.d_in, 'ro-', 5)
        self.plot_helper(self.d_out, 'cv-', 5)

        plt.legend(['Original Sequence In-degree', 'Origianl Sequence Out-degree',
                    'Equal-sum Sequence In-degree', 'Equal-sum Sequence Out-degree'])
        plt.xlabel('Degree')
        plt.ylabel('Number of nodes')
        plt.xlim([0, 40])

        plt.show()

    def degrees_plot(self):
        """
        method that plots the degree distribution of 
        1) bi-sequence, modified by algorithm 2.1 to make equal sum
        2) generated simple graph   
        """

        plt.figure()
        self.plot_helper(self.d_in, 'bo-', 5)
        self.plot_helper(self.d_out, 'gv-', 5)
        self.plot_helper(self.graph_din, 'ro-', 5)
        self.plot_helper(self.graph_dout, 'cv-', 5)

        plt.legend(['Equal-sum Sequence In-degree', 'Equal-sum Sequence Out-degree', 'Graph In-degree', 'Graph Out-degree'])
        plt.xlabel('Degree')
        plt.ylabel('Number of nodes')
        plt.xlim([0,40])

        plt.show()


    def wilx_test(self):
        return [st.wilcoxon(self.d_in, self.d_in_original), st.wilcoxon(self.d_out, self.d_out_original)]

    # plot first k nodes in the decreasing order of pagerank, and then plot their corresponding
    # betweenness_centrality value
    def pr_vs_bc_plot(self, k=None):
        if k is None:
            k = self.size

        plt.figure()

        pr = self.page_rank
        bc = self.betweenness_centrality

        pr_sort = sorted(pr.items(), key=operator.itemgetter(1), reverse=True)

        # nodes = [str(node[0]) for node in pr_sort ]
        pr_scores = [node[1] for node in pr_sort]
        bc_scores = [bc[node[0]] for node in pr_sort]
        bc_scaled_scores = [elem / sum(bc_scores) for elem in bc_scores]
        plt.plot(bc_scaled_scores[0: k], 'bx', markersize=3)
        plt.plot(pr_scores[0: k], 'ro', markersize=1)


        plt.legend(['Betweeness_Centrality', 'Page_Rank'])
        plt.xlabel('Node')
        plt.ylabel('Ranking')
        plt.title('Comparison between Pagerank and Betweenness centrality')

        # plot first k nodes in the decreasing order of bc, and then plot their corresponding pagerank
    def bc_vs_pr_plot(self, k=None):
        if k is None:
            k = self.size

        plt.figure()

        pr = self.page_rank
        bc = self.betweenness_centrality

        bc_sort = sorted(bc.items(), key=operator.itemgetter(1), reverse=True)

        # nodes = [str(node[0]) for node in pr_sort ]
        bc_scores = [node[1] for node in bc_sort]
        pr_scores = [pr[node[0]] for node in bc_sort]
        bc_scaled_scores = [elem / sum(bc_scores) for elem in bc_scores]
        plt.plot(pr_scores[0: k], 'ro', markersize=1)
        plt.plot(bc_scaled_scores[0: k], 'bx', markersize=3)

        plt.legend(['Page_Rank', 'Betweeness_Centrality'])
        plt.xlabel('Node')
        plt.ylabel('Ranking')
        plt.title('Comparison between Pagerank and Betweenness centrality')



    def spearman_test(self):
        pr = list(self.page_rank.values())
        bc = list(self.betweenness_centrality.values())
        corr, pvalue =st.spearmanr(pr, bc)

        return corr, pvalue




    # return to the number and the percentage of overlapping nodes in top k page-rakned
    # and top k betweenness-centrality nodes
    def overlaps(self, k):
        bc_sort = sorted(self.betweenness_centrality.items(), key=operator.itemgetter(1), reverse=True)
        pr_sort = sorted(self.page_rank.items(), key=operator.itemgetter(1), reverse=True)

        bc_topk = bc_sort[0: k]
        pr_topk = pr_sort[0: k]

        set_bc = {tup[0] for tup in bc_topk}
        set_pr = {tup[0] for tup in pr_topk}

        overlap_number = len(set.intersection(set_bc, set_pr))
        overlap_percentage = overlap_number / k

        return overlap_number, overlap_percentage


