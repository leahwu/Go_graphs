from collections import Counter
import PowerLawDistribution as pld
import matplotlib.pyplot as plt
import networkx as nx
import operator
import ValidDegree as vd
import scipy.stats as st
import DCMRevised as dcm_r

class DCMGenerator(object):

    def __init__(self, a, d, beta, n, algorithm):

        if algorithm == 'Erased':
            fg = pld.PowerLaw(a, d, beta)
            degree_seq = vd.directed_gen(d, beta, fg, n)

            # after modifying the degree sequence to make the sum(d_in) = sum(d_out) using alg 2.1
            self.d_in = degree_seq[0].tolist()
            self.d_out = degree_seq[1].tolist()

            # original degree sequence generated by fg-distribution
            self.d_in_original = degree_seq[2].tolist()
            self.d_out_original = degree_seq[3].tolist()

            # generate the multigraph
            dcm = nx.directed_configuration_model(self.d_in, self.d_out)

            # remove parallel edges
            dcm = nx.DiGraph(dcm)
            # remove self-loops
            dcm.remove_edges_from(dcm.selfloop_edges())

            # get the simple directed configuration graph
            self.graph = dcm

        if algorithm == 'Repeated':
            flag = False
            while not flag:
                fg = pld.PowerLaw(a, d, beta)
                degree_seq = vd.directed_gen(d, beta, fg, n)

                # after modifying the degree sequence to make the sum(d_in) = sum(d_out) using alg 2.1
                self.d_in = degree_seq[0].tolist()
                self.d_out = degree_seq[1].tolist()

                # original degree sequence generated by fg-distribution
                self.d_in_original = degree_seq[2].tolist()
                self.d_out_original = degree_seq[3].tolist()

                (model, flag) = dcm_r.directed_configuration_model_revised(self.d_in, self.d_out)
            self.graph = nx.DiGraph(model)


        # return to a dictionary
        self.page_rank = nx.pagerank(self.graph)
        self.betweenness_centrality = nx.betweenness_centrality(self.graph)

        self.graph_din = list(self.graph.in_degree().values())
        self.graph_dout = list(self.graph.out_degree().values())

        self.size = len(self.graph_din)


    def plot_helper(self, seq, color, ms):
        values = sorted(set(seq))
        hist = [Counter(seq)[x] for x in values]
        plt.plot(values, hist, color, ms)  # in-degree


    def test_equal_sum_algorithm(self):
        """
        method that plots the degree distribution of 
        1) bi-sequence, generated by fg-distribution
        2) bi-sequence, modified by algorithm 2.1 to make equal sum   
        """
        plt.figure()

        self.plot_helper(self.d_in_original, 'bo-', 5)
        self.plot_helper(self.d_out_original, 'gv-', 5)
        self.plot_helper(self.d_in, 'ro-', 5)
        self.plot_helper(self.d_out, 'cv-', 5)

        plt.legend(['Original Sequence In-degree', 'Origianl Sequence Out-degree',
                    'Equal-sum Sequence In-degree', 'Equal-sum Sequence Out-degree'])
        plt.xlabel('Degree')
        plt.ylabel('Number of nodes')
        plt.xlim([0, 40])

        plt.show()

    def degrees_plot(self):
        """
        method that plots the degree distribution of 
        1) bi-sequence, modified by algorithm 2.1 to make equal sum
        2) generated simple graph   
        """

        plt.figure()
        self.plot_helper(self.d_in, 'bo-', 5)
        self.plot_helper(self.d_out, 'gv-', 5)
        self.plot_helper(self.graph_din, 'ro-', 5)
        self.plot_helper(self.graph_dout, 'cv-', 5)

        plt.legend(['Equal-sum Sequence In-degree', 'Equal-sum Sequence Out-degree', 'Graph In-degree', 'Graph Out-degree'])
        plt.xlabel('Degree')
        plt.ylabel('Number of nodes')
        plt.xlim([0,40])

        plt.show()


    def wilx_test(self):
        return [st.wilcoxon(self.d_in, self.d_in_original), st.wilcoxon(self.d_out, self.d_out_original)]

    # plot first k nodes in the decreasing order of pagerank, and then plot their corresponding
    # betweenness_centrality value
    def pr_vs_bc_plot(self, k=None):
        if k is None:
            k = self.size

        plt.figure()

        pr = self.page_rank
        bc = self.betweenness_centrality

        pr_sort = sorted(pr.items(), key=operator.itemgetter(1), reverse=True)

        # nodes = [str(node[0]) for node in pr_sort ]
        pr_scores = [node[1] for node in pr_sort]
        bc_scores = [bc[node[0]] for node in pr_sort]
        bc_scaled_scores = [elem / sum(bc_scores) for elem in bc_scores]
        plt.plot(bc_scaled_scores[0: k], 'bx', markersize=3)
        plt.plot(pr_scores[0: k], 'ro', markersize=1)


        plt.legend(['Betweeness_Centrality', 'Page_Rank'])
        plt.xlabel('Node')
        plt.ylabel('Ranking')
        plt.title('Comparison between Pagerank and Betweenness centrality')

        # plot first k nodes in the decreasing order of bc, and then plot their corresponding pagerank
    def bc_vs_pr_plot(self, k=None):
        if k is None:
            k = self.size

        plt.figure()

        pr = self.page_rank
        bc = self.betweenness_centrality

        bc_sort = sorted(bc.items(), key=operator.itemgetter(1), reverse=True)

        # nodes = [str(node[0]) for node in pr_sort ]
        bc_scores = [node[1] for node in bc_sort]
        pr_scores = [pr[node[0]] for node in bc_sort]
        bc_scaled_scores = [elem / sum(bc_scores) for elem in bc_scores]
        plt.plot(pr_scores[0: k], 'ro', markersize=1)
        plt.plot(bc_scaled_scores[0: k], 'bx', markersize=3)

        plt.legend(['Page_Rank', 'Betweeness_Centrality'])
        plt.xlabel('Node')
        plt.ylabel('Ranking')
        plt.title('Comparison between Pagerank and Betweenness centrality')



    def spearman_test(self):
        pr = list(self.page_rank.values())
        bc = list(self.betweenness_centrality.values())
        corr, pvalue =st.spearmanr(pr, bc)

        return corr, pvalue

